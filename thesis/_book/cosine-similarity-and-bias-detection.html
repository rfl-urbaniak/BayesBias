<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>2 Cosine similarity and bias detection | Conceptual and methodological problems with bias detection and avoidance in natural language processing</title>
  <meta name="description" content="2 Cosine similarity and bias detection | Conceptual and methodological problems with bias detection and avoidance in natural language processing" />
  <meta name="generator" content="bookdown 0.22 and GitBook 2.6.7" />

  <meta property="og:title" content="2 Cosine similarity and bias detection | Conceptual and methodological problems with bias detection and avoidance in natural language processing" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="2 Cosine similarity and bias detection | Conceptual and methodological problems with bias detection and avoidance in natural language processing" />
  
  
  

<meta name="author" content="Alicja Dobrzeniecka" />


<meta name="date" content="2021-06-23" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="introduction.html"/>
<link rel="next" href="walkthrough-with-the-religion-dataset.html"/>
<script src="book_assets/header-attrs-2.8/header-attrs.js"></script>
<script src="book_assets/jquery-2.2.3/jquery.min.js"></script>
<link href="book_assets/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="book_assets/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="book_assets/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="book_assets/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="book_assets/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="book_assets/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="book_assets/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="book_assets/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="book_assets/anchor-sections-1.0.1/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction</a></li>
<li class="chapter" data-level="2" data-path="cosine-similarity-and-bias-detection.html"><a href="cosine-similarity-and-bias-detection.html"><i class="fa fa-check"></i><b>2</b> Cosine similarity and bias detection</a>
<ul>
<li class="chapter" data-level="2.1" data-path="cosine-similarity-and-bias-detection.html"><a href="cosine-similarity-and-bias-detection.html#word-embeddings"><i class="fa fa-check"></i><b>2.1</b> Word embeddings</a></li>
<li class="chapter" data-level="2.2" data-path="cosine-similarity-and-bias-detection.html"><a href="cosine-similarity-and-bias-detection.html#cosine-similarity-and-distance"><i class="fa fa-check"></i><b>2.2</b> Cosine similarity and distance</a></li>
<li class="chapter" data-level="2.3" data-path="cosine-similarity-and-bias-detection.html"><a href="cosine-similarity-and-bias-detection.html#cosine-distance-in-a-one-class-bias-detection"><i class="fa fa-check"></i><b>2.3</b> Cosine distance in a one-class bias detection</a></li>
<li class="chapter" data-level="2.4" data-path="cosine-similarity-and-bias-detection.html"><a href="cosine-similarity-and-bias-detection.html#cosine-distance-in-a-multi-class-bias-detection"><i class="fa fa-check"></i><b>2.4</b> Cosine distance in a multi-class bias detection</a></li>
<li class="chapter" data-level="2.5" data-path="cosine-similarity-and-bias-detection.html"><a href="cosine-similarity-and-bias-detection.html#limitations-of-the-approach"><i class="fa fa-check"></i><b>2.5</b> Limitations of the approach</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="walkthrough-with-the-religion-dataset.html"><a href="walkthrough-with-the-religion-dataset.html"><i class="fa fa-check"></i><b>3</b> Walkthrough with the religion dataset</a>
<ul>
<li class="chapter" data-level="3.1" data-path="walkthrough-with-the-religion-dataset.html"><a href="walkthrough-with-the-religion-dataset.html#loading-and-understanding-the-dataset"><i class="fa fa-check"></i><b>3.1</b> Loading and understanding the dataset</a></li>
<li class="chapter" data-level="3.2" data-path="walkthrough-with-the-religion-dataset.html"><a href="walkthrough-with-the-religion-dataset.html#first-look-at-the-empirical-distributions"><i class="fa fa-check"></i><b>3.2</b> First look at the empirical distributions</a></li>
<li class="chapter" data-level="3.3" data-path="walkthrough-with-the-religion-dataset.html"><a href="walkthrough-with-the-religion-dataset.html#looking-at-the-islam-related-words"><i class="fa fa-check"></i><b>3.3</b> Looking at the islam-related words</a></li>
<li class="chapter" data-level="3.4" data-path="walkthrough-with-the-religion-dataset.html"><a href="walkthrough-with-the-religion-dataset.html#bayesian-model-structure-and-assumptions"><i class="fa fa-check"></i><b>3.4</b> Bayesian model structure and assumptions</a></li>
<li class="chapter" data-level="3.5" data-path="walkthrough-with-the-religion-dataset.html"><a href="walkthrough-with-the-religion-dataset.html#choosing-predictors"><i class="fa fa-check"></i><b>3.5</b> Choosing predictors</a></li>
<li class="chapter" data-level="3.6" data-path="walkthrough-with-the-religion-dataset.html"><a href="walkthrough-with-the-religion-dataset.html#dataset-level-coefficients"><i class="fa fa-check"></i><b>3.6</b> Dataset-level coefficients </a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="protected-word-level-analysis.html"><a href="protected-word-level-analysis.html"><i class="fa fa-check"></i><b>4</b> Protected-word level analysis</a>
<ul>
<li class="chapter" data-level="4.1" data-path="protected-word-level-analysis.html"><a href="protected-word-level-analysis.html#model-structure-and-assumptions"><i class="fa fa-check"></i><b>4.1</b> Model structure and assumptions</a></li>
<li class="chapter" data-level="4.2" data-path="protected-word-level-analysis.html"><a href="protected-word-level-analysis.html#protected-classes-in-reddit-and-google-embeddings"><i class="fa fa-check"></i><b>4.2</b> Protected classes in Reddit and Google embeddings</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="the-role-of-debiasing.html"><a href="the-role-of-debiasing.html"><i class="fa fa-check"></i><b>5</b> The role of debiasing</a>
<ul>
<li class="chapter" data-level="5.1" data-path="the-role-of-debiasing.html"><a href="the-role-of-debiasing.html#dataset-level-coefficients-after-debiasing"><i class="fa fa-check"></i><b>5.1</b> Dataset-level coefficients after debiasing</a></li>
<li class="chapter" data-level="5.2" data-path="the-role-of-debiasing.html"><a href="the-role-of-debiasing.html#protected-classes-after-debiasing"><i class="fa fa-check"></i><b>5.2</b> Protected classes after debiasing</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="discussion-and-summary.html"><a href="discussion-and-summary.html"><i class="fa fa-check"></i><b>6</b> Discussion and summary</a></li>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html"><i class="fa fa-check"></i>Appendix</a>
<ul>
<li><a href="appendix.html#original-wordlist-from-manzini2019blacktocriminal">Original wordlist from <span class="citation">(<span>Manzini, Lim, Tsvetkov, &amp; Black, 2019</span>)</span></a>
<ul>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html#religion"><i class="fa fa-check"></i>Religion</a></li>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html#gender"><i class="fa fa-check"></i>Gender</a></li>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html#race"><i class="fa fa-check"></i>Race</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html#our-control-groups"><i class="fa fa-check"></i>Our control groups</a></li>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html#human-neutral-attributes"><i class="fa fa-check"></i>Human neutral attributes</a></li>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html#non-human-neutral-attributes"><i class="fa fa-check"></i>Non-human neutral attributes</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Conceptual and methodological problems with bias detection and avoidance in natural language processing</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="cosine-similarity-and-bias-detection" class="section level1" number="2">
<h1><span class="header-section-number">2</span> Cosine similarity and bias detection</h1>
<div id="word-embeddings" class="section level2" number="2.1">
<h2><span class="header-section-number">2.1</span> Word embeddings</h2>
<!-- [based on https://machinelearningmastery.com/what-are-word-embeddings/] -->
<p>To understand what cosine similarity measurement is, one first needs to grasp the concept of translating words to a computer-readable form. In the field of natural language processsing there are two main types of words representation — localist and distributed. One-hot encoding is an example of a method used to achieve a localist representation of words. Here, each vector contains information only about a single data point. This is achieved by first mapping categorical values (words) to integers and then to each integers a binary vector is assigned which contains only 0s except for the index of the integer, which is assigned 1. An example of a localist representation is:</p>
<table>
<thead>
<tr class="header">
<th>word</th>
<th>1</th>
<th>2</th>
<th>3</th>
<th>4</th>
<th>5</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>woman</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr class="even">
<td>man</td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr class="odd">
<td>girl</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>0</td>
</tr>
<tr class="even">
<td>boy</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>0</td>
</tr>
<tr class="odd">
<td>monarch</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>1</td>
</tr>
</tbody>
</table>
<p>In the example above it is clear that the length of the vectors increases with the number of words in a vocabulary. It is not a very computationally efficient representation. It has other flaws as well. For example, it is unable to capture the resemblance between words appearing in similar contexts.</p>
<p>In contrast to the localist representation, a distributed representation returns vectors that contain continuous values instead of discrete 1s and 0s. Word embeddings are a class of various techniques that allow one to represent words as distributed vectors. Such learned representations of text have certain properties. At least prima facie, they store similar (or at least co-occurring) words close to each other in a vector space. An example of distributed representation is:</p>
<table>
<thead>
<tr class="header">
<th>word</th>
<th>1</th>
<th>2</th>
<th>3</th>
<th>4</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>woman</td>
<td>0.456</td>
<td>0.267</td>
<td>0.675</td>
<td>0.131</td>
</tr>
<tr class="even">
<td>man</td>
<td>0.451</td>
<td>0.897</td>
<td>0.472</td>
<td>0.088</td>
</tr>
<tr class="odd">
<td>girl</td>
<td>0.604</td>
<td>0.262</td>
<td>0.414</td>
<td>0.706</td>
</tr>
<tr class="even">
<td>boy</td>
<td>0.279</td>
<td>0.172</td>
<td>0.475</td>
<td>0.010</td>
</tr>
<tr class="odd">
<td>monarch</td>
<td>0.565</td>
<td>0.678</td>
<td>0.463</td>
<td>0.975</td>
</tr>
</tbody>
</table>
<p>One of the advantages of using a distributed representation is that one is able to represent an enormous number of concepts with a smaller number of units. It is also possible to better capture similarities as words of similar meanings can have similar numeric vectors.</p>
<p>The numbers occurring in such representations are not random. They are learned in a process that uses a very shallow neural network. There are various types of techniques used for learning the vectors representations. One of the most straightforward ones is a skip-gram model.
Given a word, the model tries to predict its neighboring words from the sentence. The mathematics behind the process relies on the idea that the prediction concerns the conditional probability of the adjacent words. The algorithm tries to minimize the loss function, which penalizes the system for discrepancy with actual co-occurrence frequencies in the corpus. One can choose various parameters of the model, such as the window size that determines how many surrounding words the model should predict. After preparing such a fitted model, one takes only the learned weights from a neural network, and uses them as vectors in a word embeddings representation.</p>
<p>Word embeddings have many applications in natural language processing. They are handy in document search and information retrieval. They also play their part in improving automatic translations. Well learned word representations may also contribute to the improvement of sentiment analysis or spam detection.</p>
</div>
<div id="cosine-similarity-and-distance" class="section level2" number="2.2">
<h2><span class="header-section-number">2.2</span> Cosine similarity and distance</h2>
<!-- [based on https://deepai.org/machine-learning-glossary-and-terms/cosine-similarity] -->
<p>Cosine similarity is often used as a method of finding out whether vector representations for two words suggest that they are similar or somehow connected. Cosine similarity is the cosine of the angle between two vectors: the result of dividing their inner product (dot product usually) by the product of their magnitudes.</p>
<p>It is worth mentioning one more point concerning cosine similarity. After the vectors are normalized to have length equal to 1, the inner product itself (often dot product) is used to measure the similarity, because it then equals the cosine similarity.</p>
<p><span class="math display">\[\begin{align} \tag{Sim}
\mathsf{cosineSimilarity}(A,B) &amp; = \frac{A \cdot B}{\vert \vert A \vert \vert \,\vert \vert B \vert \vert}
\end{align}\]</span>
<!-- add information about inner product role -->
Cosine similarity is considered a proper tool for this operation as its result has a clear connection to geometry and at least for a low number of dimensions may be easily interpreted. Using this scale, one can compare vector similarities in a fairly clear manner. When the vectors are aligned perpendicularly to each other, their similarity equals 0 (which is the same as the cosine of 90 degrees). This tells us that the similarity between the vectors is small. As the angle between vectors decreases, cosine similarity approaches one, which stands for the greatest similarity. It is also possible to obtain negative cosine similarity. If the value approaches -1, this intuitively means that the words are contrary to each other.</p>
<!-- todo: plotting exemplary vectors in 2d -->
<p>One of the limitations of this measure is that it informs us only about similarities between vectors in terms of their orientation. However, it is often argued that in comparing words in terms of this metric, the magnitude of vectors may be treated as irrelevant, as the most important information pertains to direction. <!-- todo: find reference--></p>
<p>In what follows, it is important to distinguish between cosine similarity and cosine distance, defined as:
<span class="math display">\[\begin{align} \tag{Sim}
\mathsf{cosineDistance}(A,B) &amp;  = 1 - \mathsf{cosineSimilarity}(A,B)\\
 &amp;  = 1 - \frac{A \cdot B}{\vert \vert A \vert \vert \,\vert \vert B \vert \vert} \nonumber
\end{align}\]</span></p>
<p>The greater the similarity between two vectors, the smaller the distance between them. The cosine distance ranges between 0 and 2. If the vectors are in an opposite directions, the cosine distance is 2. And if the vectors are extremely similar then the cosine distance is very close to 0.</p>
<p>One should note that cosine distance is not exactly a distance measure, as it does not meet triangle inequality requirements. The triangle inequality formula says that for any triangle, the sum of the lengths of any two sides must be greater than or equal to the length of the remaining side. As shown in <a href="https://stats.stackexchange.com/questions/198080/proving-that-cosine-distance-function-defined-by-cosine-similarity-between-two-u">discussion in stats.stackexchange.com</a><a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a> in the case of cosine distance it would have to fulfill this equation <span class="math inline">\(1+\mathsf{cos-sim}(A,C) &lt; \mathsf{cos-sim}(A,B) + \mathsf{cos-sim}(B,C)\)</span>. If one chooses specific unit vectors it is easy to demonstrate that the triangle inequality is not preserved.</p>
</div>
<div id="cosine-distance-in-a-one-class-bias-detection" class="section level2" number="2.3">
<h2><span class="header-section-number">2.3</span> Cosine distance in a one-class bias detection</h2>
<!-- https://arxiv.org/pdf/1607.06520.pdf -->
<!-- source of plot https://www.kaggle.com/rtatman/gender-bias-in-word-embeddings -->
<p><span class="citation"><a href="#ref-Bolukbasi2016Man" role="doc-biblioref">Bolukbasi, Chang, Zou, Saligrama, &amp; Kalai</a> (<a href="#ref-Bolukbasi2016Man" role="doc-biblioref">2016</a>)</span> define similarity between words as the outcome inner product of their normalized vectors.
They focus on examining what the geometry of a word embedding is in regard to “he” and “she” words. In other words, whether the similarity between those concepts and other words reflects expected gender stereotypes. They test this hypothesis by investigating whether there is a connection between word embeddings representing certain professions and words referring to gender. They also evaluate whether automatically produced analogies between words reflect the stereotypes as well.</p>
<p>Here the gender bias of a word <span class="math inline">\(w\)</span> is understood as its projection on the gender direction <span class="math inline">\(\vec{w} \cdot (\overrightarrow{he} - \overrightarrow{she})\)</span> (the gender direction is the top principal compontent of ten gender pair difference vectors). The underlying idea is that no bias is present if non-explicitly gender words are in equal distance to both elements in all explicitly gender pairs. Given the (ideally) gender neutral words <span class="math inline">\(N\)</span> and the gender direction <span class="math inline">\(g\)</span> the direct direct gender bias is defined as the average distance of the words in <span class="math inline">\(N\)</span> from <span class="math inline">\(g\)</span> (<span class="math inline">\(c\)</span> is a parameter determining how strict we want to be):
<span class="math display">\[\begin{align}
\mathsf{directBias_c(N,g)} &amp; = \frac{\sum_{w\in N}\vert \mathsf{cos}(\vec{w},g)\vert^c}{\vert N \vert }
\end{align}\]</span></p>
<p>A very vivid way to follow their method of arguing that bias in word embeddings is real is to plot the values of inner product of chosen words. The plot below does not originate from the original paper but from <a href="https://www.kaggle.com/rtatman/gender-bias-in-word-embeddings">kaggle.com R notebook using data from GloVe: Global Vectors for Word Representation</a>.<a href="#fn3" class="footnote-ref" id="fnref3"><sup>3</sup></a> However, similar visualization may be found there. Data used to create our plot is as follows.</p>
<p>Occupations associated with feminine: </p>
<p>Occupations associated with masculine: </p>
<p><img src="_main_files/figure-html/unnamed-chunk-1-1.png" width="100%" style="display: block; margin: auto;" />
</p>
<p>The points in the plot above result from the calculation of the inner product of a chosen vector for a profession word and a vector for a gender word (she or he). Inner product of two vectors expresses similarity between words. This assumption originates from the geometry and properties of a vector space. In the picture one may observe a correlation between the occupation and gender. Stereotypical male professions are closer to the “he” word and stereotypical female professions have greater similarity with “she” word. One could argue that this is a hint that there is some hidden bias information stored in the words vectors.</p>
<!-- todo: shortly describe what they do later and how they verify if it was removed - analogies etc. -->
</div>
<div id="cosine-distance-in-a-multi-class-bias-detection" class="section level2" number="2.4">
<h2><span class="header-section-number">2.4</span> Cosine distance in a multi-class bias detection</h2>
<!-- [article https://arxiv.org/pdf/1904.04047.pdf] -->
<p><span class="citation"><a href="#ref-Manzini2019blackToCriminal" role="doc-biblioref">Manzini, Lim, Tsvetkov, &amp; Black</a> (<a href="#ref-Manzini2019blackToCriminal" role="doc-biblioref">2019</a>)</span> present a different approach towards finding similarities between classes of words. Cosine distance is used in the article as a measure to first argue for the existence of multi-class bias and then to show how through bias mitigation techniques the bias may be decreased.</p>
<p>They modify WEAT to a multi-class setting, introducing Mean Average Cosine similarity as a measure of bias (in fact, in the paper they report distances rather than similarities). Let <span class="math inline">\(T = \{t_1, \dots, t_k\}\)</span> be a class of protected word embeddings, and let each <span class="math inline">\(A_j\in A\)</span> be a set of attributes stereotypically associated with a protected word). Then:
<span class="math display">\[\begin{align}
S(t_i, A_j) &amp; = \frac{1}{\vert A_j\vert}\sum_{a\in A_j}\mathsf{cos}(t,a) \\
MAC(T,A) &amp; = \frac{1}{\vert T \vert \,\vert A\vert}\sum_{t_i \in T }\sum_{A_j \in A} S(t_i,A_j)
\end{align}\]</span></p>
<p>As the code has been provided by the authors we were able to reconstruct their results. The main steps in the procedure are as follows. Let us go through an example that refers to the process of hard debiasing on religious attributes.</p>
<p>First we load word embeddings from reddit.US.txt.tok.clean.cleanedforw2v.w2v dataset. The word embeddings have only 50 dimensions and the number of individual words from the dataset is 44895. The authors assume that the protected group should ideally not have high cosine similarity to stereotypical words. The word embeddings geometry should not place this group close to harmful stereotypes, if it is to be bias-free. For instance, let’s look at the religion-related words.</p>
<p>Protected words by religion type:</p>
<p>Stereotypical words by religion type:</p>
<p>We have prepared a table presenting the values of cosine distance for each protected word with each attribute (stereotype). The part of the results is shown in Table 2.3</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="cosine-similarity-and-bias-detection.html#cb1-1" aria-hidden="true" tabindex="-1"></a>religion <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(<span class="st">&quot;../datasets/religionReddit.csv&quot;</span>)[<span class="sc">-</span><span class="dv">1</span>]</span>
<span id="cb1-2"><a href="cosine-similarity-and-bias-detection.html#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="fu">colnames</span>(religion) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;protectedWord&quot;</span>,<span class="st">&quot;wordToCompare&quot;</span>,<span class="st">&quot;wordClass&quot;</span>,</span>
<span id="cb1-3"><a href="cosine-similarity-and-bias-detection.html#cb1-3" aria-hidden="true" tabindex="-1"></a>                        <span class="st">&quot;cosineDistance&quot;</span>,<span class="st">&quot;cosineSimilarity&quot;</span>,<span class="st">&quot;connection&quot;</span>)</span>
<span id="cb1-4"><a href="cosine-similarity-and-bias-detection.html#cb1-4" aria-hidden="true" tabindex="-1"></a>religion<span class="sc">$</span>wordClass <span class="ot">&lt;-</span> <span class="fu">as.factor</span>(religion<span class="sc">$</span>wordClass)</span>
<span id="cb1-5"><a href="cosine-similarity-and-bias-detection.html#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="fu">levels</span>(religion<span class="sc">$</span>wordClass) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;christian&quot;</span>,<span class="st">&quot;human&quot;</span>,<span class="st">&quot;jewish&quot;</span>,<span class="st">&quot;muslim&quot;</span>,<span class="st">&quot;neutral&quot;</span>)</span>
<span id="cb1-6"><a href="cosine-similarity-and-bias-detection.html#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(religion)  <span class="sc">%&gt;%</span>  <span class="fu">kable</span>(<span class="at">format =</span> <span class="st">&quot;latex&quot;</span>,<span class="at">booktabs=</span>T,</span>
<span id="cb1-7"><a href="cosine-similarity-and-bias-detection.html#cb1-7" aria-hidden="true" tabindex="-1"></a>                      <span class="at">linesep =</span> <span class="st">&quot;&quot;</span>,  <span class="at">escape =</span> <span class="cn">FALSE</span>, </span>
<span id="cb1-8"><a href="cosine-similarity-and-bias-detection.html#cb1-8" aria-hidden="true" tabindex="-1"></a>                      <span class="at">caption =</span> <span class="st">&quot;Head of the religion dataset.&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb1-9"><a href="cosine-similarity-and-bias-detection.html#cb1-9" aria-hidden="true" tabindex="-1"></a>                      <span class="fu">kable_styling</span>(<span class="at">latex_options=</span><span class="fu">c</span>(<span class="st">&quot;scale_down&quot;</span>))</span></code></pre></div>
<div style="page-break-after: always;"></div>
<p>In the article there was no analysis of individual distances, but the general look at the means. The authors introduced a metric that tries to generalize WEAT in measuring the presence of bias through the classification of multi-class bias in groups of words connected with gender, religion or race. In the process they first take the mean of cosine distances between a given protected word and attributes assigned to each stereotype. They do not differentiate between stereotypes associated with a word and stereotypes associated with different words (in the case of religion, stereotypes characteristic for Christianity has also cosine distance measured with for instance, Judaism or Islam). Then, after collecting the list of mean cosine distances, they average the list to obtain one final value representing the whole group, in this example religion, for which the final mean of all mean distances is equal to 0.859.</p>
<p>In the article the authors also try to remove biases, as previously defined, from a word embedding. First they identify the bias subspace using Principal Component Analysis (PCA) which is a technique for dimensionality reduction. It is applied here to choose the subspace that contains the greatest amount of information. There can be many subspaces found in a given group. For example in terms of religion one can identify at least a few sets that are to grasp the concept of religion in general:</p>
<p>The idea is to find a set that provides enough information to create from it a vector representing the concept of religion among words. This strategy is based on the idea that different dimensions of vectors contain different types of information and in some words in vector layers (subspaces) the information about religiousness is implicitly conveyed. In some cases this knowledge is useful, but in the case of harmful stereotypes one does not want to include the concept of religion in stereotypical words.</p>
<p>After finding the bias subspace, they use it to modify the vector values individually so that their cosine distances towards certain words are changed. In the case of stereotypes the aim is to make the cosine distances larger so that the association between protected word and stereotype is smaller.</p>
<p>In the final step they evaluate the results. The cosine distances are calculated again but this time using the debiased vocabulary. After taking the mean of all distances one final value is obtained and then it is compared with the average value from the beginning. If the cosine distances are on average greater than before then it leads the authors to the conclusion that improvement has been achieved. As the cosine distance increases, it is assumed that the association between protected and stereotypical words decreases.</p>
</div>
<div id="limitations-of-the-approach" class="section level2" number="2.5">
<h2><span class="header-section-number">2.5</span> Limitations of the approach</h2>
<p></p>
<!-- TODO: Universal ways to decide on the quality and type of attributes so that the research is significant? -->
<p>The attributes are taken from different sources, there is no principled justification for their choice. From our analysis it will become clear that the list is rather uneven.</p>
<p>There is no mention of methodology for deciding on the number of attributes necessary to decide a hypothesis on the given size of dataset. There are however some ways to estimate sample sizes needed to ensure that the results are meaningful if the effect is present. Our research will show that the numbers used
are rather insufficient.</p>
<p></p>
<p>The authors use the mean of mean average cosine similarities to measure multi-class similarity between protected word and harmful stereotypes. They average the results until they obtain one final value to represent the mean cosine distance between protected word from a given class and the attributes of that class. If one takes closer look at the individual values that are taken for the calculations it turns out that there is a bunch of outliers and surprisingly dissimilar words. We approach this issue by providing the tables and visualizations of individual cosine distances to make sure that we obtain a proper insight into the data.</p>
<p></p>
<p>With such a method the uncertainty involved is not really considered which makes it even more difficult to give reasonable interpretations of the results. We propose the use of Bayesian method to obtain some understanding of the influence the uncertainty has on the interpretation of final results.</p>
<p></p>
<p>In the original paper, words from all three religions were compared against all of the stereotypes, which means that there was no distinction between cases in which the stereotype is associated with a given religion, as opposed to the situation in which it is associated with another one. Not all of the stereotypical words have to be considered as harmful for all of the religions. One should investigate the religions separately as some of them may have stronger harmful associations that others. One should also include control groups to have a way of comparing the stereotypical results with neutral or human-like words. Later in the text we will explain in details reasons for introducing control groups. In our analysis, we distinguish between stereotypes associated with a given group, stereotypes associated with different groups, and control groups: neutral words and stereotypes-free human predicates.</p>
<p></p>
<p>Assuming for a moment that the value of multi-class cosine distance is correct, one may question the interpretation. <span class="citation"><a href="#ref-Manzini2019blackToCriminal" role="doc-biblioref">Manzini, Lim, Tsvetkov, &amp; Black</a> (<a href="#ref-Manzini2019blackToCriminal" role="doc-biblioref">2019</a>)</span> summarize the averages of cosine distance per group (gender, race, religion). For now let us focus now on analyzing the values relating to religious biases. Here is the relevant fragment of table:</p>
<table>
<thead>
<tr class="header">
<th>Religion Debiasing</th>
<th>MAC</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Biased</td>
<td>0.859</td>
</tr>
<tr class="even">
<td>Hard Debiased</td>
<td>0.934</td>
</tr>
<tr class="odd">
<td>Soft Debiased (<span class="math inline">\(\lambda\)</span> = 0.2)</td>
<td>0.894</td>
</tr>
</tbody>
</table>
<p>MAC stand for mean average cosine similarity, although in reality the the table contains mean distances. What may attract attention is the fact that the value of cosine distance in “Biased” category is already quite high even before debiasing. High cosine distance indicates low cosine similarity between values. One could think that average cosine similarity equal to approximately 0.141 is not significant enough to consider it as bias. However the authors aim to mitigate “biases” in vectors with such great distance to make it even larger. Methodologically the question is, on what basis is this small similarity still considered as a proof of the presence of bias, and whether these small changes are meaningful. This is in general the problem of scale and the lack of universal intervals. In contrast, statistical intervals will help us decide whether a given cosine similarity is high enough to consider the words to be more similar than if we chose them at random. We will use highest posterior density intervals, in line with Bayesian methodology.</p>
<p></p>
<p>In our case, the curse of dimensionality may take place when there is an increase in the volume of data that results in adding extra dimensions to the Euclidean space. According to the article
<a href="https://analyticsindiamag.com/curse-of-dimensionality-and-what-beginners-should-do-to-overcome-it/">Curse of dimensionality at analyticsindiamag.com</a> as the number of features increases, it may be harder and harder to obtain useful information from the data using the available algorithms. One may notice that more data should contribute to greater amount of information, but more information also means greater risk of noise and distractions in data. At the same time, modern solutions are often adapted to smaller dimensions and their results in higher ones are not intuitive, or may be prone to error.</p>
<p>Using cosine similarity in high dimensions in word embeddings may also be prone to the curse of dimensionality. According to <span class="citation"><a href="#ref-Venkat2018Curse" role="doc-biblioref">Venkat</a> (<a href="#ref-Venkat2018Curse" role="doc-biblioref">2018</a>)</span> there are reasons to consider this phenomenon when searching for word similarities in higher dimensions. An experiment is conducted that aims at showing how the similarity values and variation change as the number of dimensions increases. The hypothesis made in the paper states that two things will happen as the number of dimensions increase. First, the effort required to measure cosine similarity will be greater, and two, the similarity between data will blur out and have less variation. The authors generate random points with increasing number of dimensions where each dimension of a data point is given a value between 0 and 1. Then they pick one vector at random from each dimension class and calculate the cosine similarity between the chosen vector and the rest of the data. Then they check how the variation of values changes as the number of dimensions increases. It seems like the more dimensions there are, the smaller the variance and therefore it is less obvious how to interpret the resulting cosine similarities. Maybe the scale should be adjusted to the number of dimensions and variance so that it still gives us sensible information about data. Yet, according to some articles cosine similarity in high dimensions is not reliable enough as it may be the case that choosing words at random may result in similar values as when picking them consciously.</p>
<div class="figure">
<img src="../images/curseOfDimensionality.png" alt="" />
<p class="caption">curse of dimensionality, number of dimensions on the x axis, standard deviation of similarity on the y axis</p>
</div>

</div>
</div>
<h3>References</h3>
<div id="refs" class="references csl-bib-body hanging-indent" line-spacing="2">
<div id="ref-Bolukbasi2016Man" class="csl-entry">
Bolukbasi, T., Chang, K.-W., Zou, J. Y., Saligrama, V., &amp; Kalai, A. (2016). Man is to computer programmer as woman is to homemaker? Debiasing word embeddings. <em>CoRR</em>, <em>abs/1607.06520</em>. Retrieved from <a href="http://arxiv.org/abs/1607.06520">http://arxiv.org/abs/1607.06520</a>
</div>
<div id="ref-Manzini2019blackToCriminal" class="csl-entry">
Manzini, T., Lim, Y. C., Tsvetkov, Y., &amp; Black, A. W. (2019). Black is to criminal as caucasian is to police: Detecting and removing multiclass bias in word embeddings. Retrieved from <a href="http://arxiv.org/abs/1904.04047">http://arxiv.org/abs/1904.04047</a>
</div>
<div id="ref-Venkat2018Curse" class="csl-entry">
Venkat, N. (2018). The curse of dimensionality: Inside out.
</div>
</div>
<div class="footnotes">
<hr />
<ol start="2">
<li id="fn2"><p><a href="https://stats.stackexchange.com/questions/198080/proving-that-cosine-distance-function-defined-by-cosine-similarity-between-two-u" class="uri">https://stats.stackexchange.com/questions/198080/proving-that-cosine-distance-function-defined-by-cosine-similarity-between-two-u</a><a href="cosine-similarity-and-bias-detection.html#fnref2" class="footnote-back">↩︎</a></p></li>
<li id="fn3"><p><a href="https://www.kaggle.com/rtatman/gender-bias-in-word-embeddings">https://www.kaggle.com/rtatman/gender-bias-in-word-embeddings</a>.<a href="cosine-similarity-and-bias-detection.html#fnref3" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="introduction.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="walkthrough-with-the-religion-dataset.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="book_assets/gitbook-2.6.7/js/app.min.js"></script>
<script src="book_assets/gitbook-2.6.7/js/lunr.js"></script>
<script src="book_assets/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="book_assets/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="book_assets/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="book_assets/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="book_assets/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="book_assets/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="book_assets/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["_main.pdf"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
