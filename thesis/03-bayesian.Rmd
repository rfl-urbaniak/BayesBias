# Bayesian analysis of cosine-based bias




We start with loading the libraries needed for the analysis.

\footnotesize
```{r,echo=TRUE,eval=TRUE,fig.align = "center",cache=TRUE, fig.show = "hold", out.width = "100%", warning = FALSE, message = FALSE}
library(ggplot2)
library(ggthemes)
library(rethinking)
library(tidyverse)
library(ggpubr)
library(kableExtra)
library(dplyr)
library(ggExtra)
library(cowplot)
```
\normalsize 





# Walkthrough with the religion dataset


We will use the choice of protected words and stereotypical predicates used in REF. This is a decent point of departure,  not only we want to compare our method to that of REF, but also because this data format is fairly general (as contrasted, say, with a set up for binary stereotypes). Note also that the method we develop here  can fairly easily be  run  for different stereotypization patterns.  Let's start  with  explaining the method and its deployment using a dataset obtained for the religion-related protected words.

Let's load, clean a bit and inspect the head of the religion dataset we prepared.  In order to obtain this  dataset, we  calculated the cosine distance between each protected word and each word from both the bias-related attribute groups, which were used in the original study, and to neutral and human control attributes which we added  as control groups.  For instance, for religion, the bias-related predicates (coming from the original study in REF) include muslim bias attributes, jew bias attributes, christian bias attributes (see a list in the APPENDIX).  

We decided to add control groups in the form of two classes --- neutral words and human-related words. Without a proper control group it is quite hard to compare the resulting cosine distances and decide on their significance in bias detection. We prepared approximately 300\todo{FIX later} more or less neutral words to double-check the prima-facie neutral hypothesis that their cosine similarity to the protected words will oscillate around 0 (that is, the distances will be around 1). This provides us with a  more reliable point of reference. Moreover, we added human attributes that are associated with people in general to investigate  whether the smaller cosine distance between protected words and stereotypes can result  simply from the fact that the stereotype predicates  are associated with humans. For two control groups, we have randomly drawn 300 words that do not express any property usually attributed to humans, and human attributes. \todo{describe once the words are selected}

<!-- In other words, we took each protected word and in nested iteration calculated all of the cosine distances between the word and all available harmful stereotypes, neutral words, and human ones, which resulted with approximately 333 cosine distances per each protected word. -->

\vspace{1mm}
\footnotesize

```{r religionTableHead,echo=TRUE,eval=TRUE,fig.align = "center",cache=TRUE, fig.show = "hold", out.width = "100%"}
religion <- read.csv("../datasets/religionReddit.csv")[-1]
colnames(religion) <- c("protectedWord","wordToCompare","wordClass",
                        "cosineDistance","cosineSimilarity","connection")
levels(religion$wordClass) <- c("christian","human","jewish","muslim","neutral")
head(religion)  %>%  kable(format = "latex",booktabs=T,
                      linesep = "",  escape = FALSE, 
                      caption = "Head of the religion dataset.") %>%
                      kable_styling(latex_options=c("scale_down"))
```
\normalsize





 The `protectedWord` column contains words from a protected class that (in a perfect world according to the assumptions of the orignal study) should not be associated with  harmful stereotypes. `wordToCompare` contains attributes, including stereotypes and control group words. For each row we compute the cosine distances between a given protected  word and a given attribute word. `wordClass` tells us  which class an attribute is supposed to be stereotypically associated with, that is, whether the  word from `wordToCompare` is associated stereotypically with jews, christians or muslims, or whether it belongs to a control group. `cosineDistance` is simply a calculation of the cosine distance between protected word and atrribute.  `cosineSimilarity`  contains the result of substracting cosine distance from 1. `connection` contains information about  the relation type between a protected word and an attribute. If the attribute is e.g. a harmful jewish stereotype and the protected word is also from the judaism group,  the connection has value `associated`.  If the attribute is still stereotypically jewish, but the protected word comes from another religion, the connection is labelled as  `different`. If the attribute belongs to  a neutral group then the connection is labelled as `none` and if an attribute belongs to the `human` class, then the connection is labelled as `human`. 




First let's take a look at the empirical distribution of distances by the connection type, initially ignoring the human control class for now.

\vspace{1mm}
\footnotesize
```{r,echo=FALSE,eval=TRUE,fig.align = "center",cache=TRUE, fig.show = "hold", out.width = "100%"}
religionNoHumans <- religion[religion$connection !="human",]

ggplot(religionNoHumans, aes(x =  cosineDistance, fill = connection, color = connection ))+geom_density(alpha=0.6,size = .2)+theme_tufte()+ggtitle("Empirical distribution of cosine distances (religion), no human attributes.")+ scale_fill_manual(values = c("orangered4","chartreuse4","gray"))+scale_x_continuous(breaks = seq(0.3,1.5, by = 0.1))+xlab("cosine distance")+ scale_color_manual(values = c("orangered4","chartreuse4","gray"))
```
\normalsize

The first impression is that while  there is a  shift for  associated words towards smaller cosine distances as compared to the neutral words, slightly surprisingly a slightly weaker shift in the same direction is visible for attributes associated with different stereotypes. Moreover,  the empirical distributions overlap to alarge extent and the  means grouped by connection type do not seem too far from each other. In fact, as there is a lot of  variety in the consine distances (as we will soon see), abd we need to gauge the uncertaintly involved, and  to look more carefully at individual protected words to get a better idea of how the cosine distance distribution changes for different attribute groups and different protected classes.   Now, let's add the human attributes to the picture:


\vspace{1mm}
\footnotesize
```{r,echo=FALSE,eval=TRUE,fig.align = "center",cache=TRUE, fig.show = "hold", out.width = "100%"}
ggplot(religion, aes(x =  cosineDistance, fill = connection, color = connection))+geom_density(alpha=0.6,size = .2)+theme_tufte()+ggtitle("Empirical distribution of cosine distances (religion)")+ scale_fill_manual(values = c("orangered4","chartreuse4", "skyblue", "gray"))+scale_x_continuous(breaks = seq(0.3,1.5, by = 0.1))+xlab("cosine distance")+ scale_color_manual(values = c("orangered4","chartreuse4","skyblue","gray"))
```
\normalsize


\noindent Notice that the distribution for `human` (even though we did our best not to include in it any stereotype-related atributes) is left-skewed, with much overlap with `associated` and `different`, which illustrates the need to take being associated with humans as an important predictor.





Our focus lies in  `connection` as a predictor. Morever, later on we'll be interested in looking at the protected words separately, and at protected words split by connection. For technical reasons it is useful to represent these factors as integer vectors.

\vspace{1mm}
\footnotesize
```{r,echo=TRUE,eval=TRUE,fig.align = "center",cache=TRUE, fig.show = "hold", out.width = "100%"}
religion$con <- as.integer(religion$connection)
religion$pw <- as.integer(religion$protectedWord)
religion$pwFactor <- factor(paste0(religion$protectedWord, religion$connection))
religion$pwIndex <- as.integer(religion$pwFactor)
```
\normalsize

<!-- For technical reasons it is useful to represent an $n$-level factor with $n-1$ binary vectors. `connection` in this case has four levels. -->


<!-- \vspace{1mm} -->
<!-- \footnotesize -->
<!-- ```{r,echo=TRUE,eval=TRUE,fig.align = "center",cache=TRUE, fig.show = "hold", out.width = "100%"} -->
<!-- religion$associated <- ifelse(religion$connection == "associated", 1, 0) -->
<!-- religion$different <- ifelse(religion$connection == "different", 1, 0) -->
<!-- religion$human <- ifelse(religion$connection == "human" |religion$connection == "associated"| -->
<!--                            religion$connection == "different", 1, 0)   -->
<!-- ```   -->
<!-- \normalsize -->



A short script, `cleanDataset` to make this faster, so equivalently:

\vspace{1mm}
\footnotesize
```{r,echo=TRUE,eval=TRUE,fig.align = "center",cache=TRUE, fig.show = "hold", out.width = "100%"}
source("../functions/cleanDataset.R")
religion <- read.csv("../datasets/religionReddit.csv")[-1]
religion <- cleanDataset(religion,c("christian","human","jewish","muslim","neutral"))
```
\normalsize



For now, let's focus on five protected words related to islam ("imam", "islam", "mosque", "muslim", and "quran"). The word list associates with islam  four stereotypical attributes ("violent", "terrorist", "uneducated" and "dirty").  First, we select and plot the empirical distributions for these protected words.


\vspace{1mm}
\footnotesize
```{r,echo=TRUE,eval=TRUE,fig.align = "center",cache=TRUE, fig.show = "hold", out.width = "100%",message =FALSE, warning = FALSE}
library(tidyverse)
muslimWords <- c("imam","islam","mosque","muslim","quran")
muslim <- religion %>% filter(protectedWord %in% muslimWords)
ggplot(muslim, aes(x =  cosineDistance, fill = connection, color = connection))+
  geom_density(alpha=0.6,size = .2)+ 
  scale_fill_manual(values = c("orangered4","chartreuse4", "skyblue", "gray"))+
  scale_x_continuous(breaks = seq(0.3,1.5, by = 0.1))+xlab("cosine distance")+
  scale_color_manual(values = c("orangered4","chartreuse4","skyblue","gray"))+
  theme_tufte()+ggtitle("Empirical distribution of distances (muslim)")
```
\normalsize

\noindent Once we focus on words related to islam, the associated bias seems to be stronger than in the whole dataset.  This is a  step towards illustrating that the distribution of bias is uneven. 


Now, say we want to look at a single protected word. Since the dataset also contains comparison multiple control neutral and  human attributes, we randomly select only 5 from `none` and 5 from `human` control groups of those for the visualisation purposes.


\vspace{1mm}
\footnotesize
```{r tableMuslimActive,echo=TRUE,eval=TRUE,fig.align = "center",cache=FALSE, fig.show = "hold", out.width = "100%"}
library(tidyverse)
muslimClass <- muslim %>% filter(protectedWord == "muslim")
neutralSample <- sample_n(filter(muslimClass,connection == "none"), 5)
humanSample <- sample_n(filter(muslimClass,connection == "human"), 5)
muslimVis <- muslimClass %>% filter(connection != "none" & connection !="human")
muslimVis <- rbind(muslimVis,neutralSample,humanSample)

#we plug in our visualisation script
source("../functions/visualisationTools.R")
#two arguments: dataset and protected word
visualiseProtected(muslimVis,"muslim")
```
\normalsize

Note that the distance between the grey point and the other points is proportional to cosine distance, the non-grey point size is proportional to cosine similarity to the protected word, and color groups by the connection type.  So for `muslim` it seems that the stereotypes coming from the word list are fairly well visible. To give you some taste of how uneven the dataset is, compare this to what happens with `priest`.

\vspace{1mm}
\footnotesize
```{r,echo=TRUE,eval=TRUE,fig.align = "center",cache=TRUE, fig.show = "hold", out.width = "100%"}
library(tidyverse)
priestClass <- religion %>% filter(protectedWord == "priest")
neutralSample <- sample_n(filter(priestClass,connection == "none"), 5)
humanSample <- sample_n(filter(priestClass,connection == "human"), 5)
priestVis <- priestClass %>% filter(connection != "none" & connection !="human")
priestVis <- rbind(priestVis,neutralSample,humanSample)

#we plug in our visualisation script
source("../functions/visualisationTools.R")
#two arguments: dataset and protected word
visualiseProtected(priestVis,"priest")
```
\normalsize

\noindent Here you can see that some human attributes are closer than stereotype attributes, and that there is no clear reason to claim that `associated` attributes are closer than `different`  or `human` attributes. This, again, illustrates the need of case-by-case analysis with  control groups. 

The general idea now is that the word lists provided in different pieces of research are just samples of attributes associates with various stereotypes and should be treated as such: the uncertaintly involved and the sample sizes should have clear impact on our estimates. 


We will now think of cosine distance as the output variable, and 
will build a few bayesian models to compare. First, we just build a baseline model which estimates cosine distance to the attributes separately for each protected word. The underlying idea is that different protected words migh in general have different relations to all the attributes and this relations should be our point of departure.

Here is the intution behind the mathematical Bayesian model involved. Our outcome variable is `cosine difference`, which we take to me normally distributed around the predicted mean for a given protected word (that is, we assume the residuals are normally distributed). The simplest  model specification is:

\begin{align}
cosineDistance_i  & \sim dnorm(\mu_i, \sigma) \\
\mu_i & = m_{pw} \\
m_{pw} & ~ dnorm(1,.5) \\
\sigma &\sim  dcauchy(0,1)
\end{align}


That is, we assume the estimated means might be different for diferent protected words and our prior for the mean and the overal standard deviation are normal with mean 1 and sd=.5 and half-cauchy with parameters `0,1`. Further on we'll also estimate additional impact the connection type may have. For this impact we take a slightly skeptical prior centered around 0 distributed normally with sd = 1. These are fairly weak and slightly skeptical regularizing priors, which can be illustrated as follows:

\vspace{2mm}

```{r priorsVis,echo=FALSE,eval=TRUE,fig.align = "center",cache=FALSE, fig.show = "hold", out.width = "100%", fig.caption = "Regularizing priors for the bayesian models."}
library(ggpubr)
sim <- seq(-1,1,by = 0.001)
dis <- 1-sim

p <- ggplot(data = data.frame(distance = dis), 
            mapping = aes(x = distance))+theme_tufte()

none <- function(x) dnorm(x,1,.5)
cau <- function(x) dcauchy(x,0,1)
par <- function(x) dnorm(x,0,1)

noneG <- p + stat_function(fun = none)+xlim(c(-0.5,2.5))+ggtitle("Prior for mean distances")
parG <- p + stat_function(fun = par)+xlim(c(-2,2))+xlab("distance change")+ggtitle("Prior for coefficients")
cauG <- p + stat_function(fun = cau)+xlim(c(0,2))+ggtitle("Prior for standard deviation")+xlab("distance change")
ggarrange(noneG,cauG, parG, ncol = 1)
```




Now we can define and compile the baseline model. Its  parameters will have a posterior distribution obtained using either Hamiltionian Monte Carlo methods (STAN) available through the `rethinking` package. 



\vspace{1mm}
\footnotesize
```{r religionBaseline,echo=TRUE,eval=FALSE,fig.align = "center",cache=TRUE, fig.show = "hold", out.width = "100%", results= "hide"}
library(rethinking)
options(buildtools.check = function(action) TRUE )
religionBaseline <- ulam(
  alist(
    cosineDistance ~ dnorm(mu,sigma),
    mu <- m[pw],
    m[pw] ~ dnorm(1,.5),
    sigma ~ dcauchy(0,1)
  ),
  data = religion,
  chains=2 , iter=4000 , warmup=1000,
  start= list(mu = 1, co = 0, sigma= .3),
  log_lik = TRUE, cores=4
)
#saving
#saveRDS(religionBaseline, 
#file = "cosineAnalysis/models/religionBaseline.rds")
```




The only reason we need it is the evaluation of connection as a predictor. Does including it in o the model improve the situation? To investigate this, let's now build a model according to the following specification: 


\begin{align}
cosineDistance_i  & \sim dnorm(\mu_i, \sigma) \\
\mu_i & = m_{pw} + co_{con}\\
m_{pw} & ~ dnorm(1,.5) \\
co_{con} & ~ dnorm(0,1) \\
\sigma &\sim  dcauchy(0,1)
\end{align}

\noindent The idea now is that each connection type comes with its own coefficient $co$ that has impact on mean distances for protected words taken separately. 

\vspace{1mm}
\footnotesize
```{r Coefsmodel,echo=TRUE,eval=FALSE,fig.align = "center",cache=TRUE, fig.show = "hold", out.width = "100%"}
library(rethinking)
options(buildtools.check = function(action) TRUE )
religionCoefs <- ulam(
  alist(
    cosineDistance ~ dnorm(mu,sigma),
    mu <- m[pw] + co[con],
    m[pw] ~ dnorm(1,.5),
    co[con] ~dnorm(0,.5),
    sigma ~ dcauchy(0,1)
  ),
  data = religion,
  chains=2 , iter=8000 , warmup=1000, 
  log_lik = TRUE
)
```
\normalsize


\noindent First, let's see if this model is really better in terms of the Widely Acceptable Information Criterion (WAIC):



\vspace{1mm}
\footnotesize
```{r,echo=TRUE,eval=TRUE,fig.align = "center",cache=TRUE, fig.show = "hold", out.width = "100%"}
#the calculation requires models which are large, we prepared the table
#compareBaseline <- print(round(compare(religionBaseline, religionCoefs)), 3)
compareBaseline <- readRDS("../datasets/compareBaseline.rds")
compareBaseline
```
\normalsize











